{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 11119767,
          "sourceType": "datasetVersion",
          "datasetId": 6934017
        },
        {
          "sourceId": 11744413,
          "sourceType": "datasetVersion",
          "datasetId": 7372605
        },
        {
          "sourceId": 13031810,
          "sourceType": "datasetVersion",
          "datasetId": 8251683
        },
        {
          "sourceId": 576369,
          "sourceType": "modelInstanceVersion",
          "isSourceIdPinned": false,
          "modelInstanceId": 266809,
          "modelId": 287881
        }
      ],
      "dockerImageVersionId": 30918,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import _LRScheduler\n",
        "\n",
        "import transformers\n",
        "from transformers import BertModel, BertTokenizerFast, AutoModel, AutoTokenizer\n",
        "import datasets\n",
        "\n",
        "import matplotlib_inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "import json\n",
        "\n",
        "from math import floor, ceil, cos, pi\n",
        "\n",
        "from scipy.stats import spearmanr, mannwhitneyu, ks_2samp\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import wandb\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
        "# torch.cuda.set_device(0)\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "%matplotlib inline\n",
        "matplotlib_inline.backend_inline.set_matplotlib_formats('pdf', 'svg')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-23T12:36:14.361720Z",
          "iopub.execute_input": "2025-10-23T12:36:14.362022Z",
          "iopub.status.idle": "2025-10-23T12:36:37.396652Z",
          "shell.execute_reply.started": "2025-10-23T12:36:14.361997Z",
          "shell.execute_reply": "2025-10-23T12:36:37.395956Z"
        },
        "id": "r_5CKWm6Tbsg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from kaggle_secrets import UserSecretsClient\n",
        "user_secrets = UserSecretsClient()\n",
        "key = user_secrets.get_secret(\"wandb_key\")\n",
        "!wandb login $key"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-23T12:36:37.397859Z",
          "iopub.execute_input": "2025-10-23T12:36:37.398169Z",
          "iopub.status.idle": "2025-10-23T12:36:40.019707Z",
          "shell.execute_reply.started": "2025-10-23T12:36:37.398138Z",
          "shell.execute_reply": "2025-10-23T12:36:40.018808Z"
        },
        "id": "2rgmQVdxTbsj",
        "outputId": "0d096aa1-8ff6-4053-b0a0-72c7cd0905fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import huggingface_hub\n",
        "huggingface_hub.login(token=user_secrets.get_secret(\"HF_TOKEN\"))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-23T12:36:40.021589Z",
          "iopub.execute_input": "2025-10-23T12:36:40.021935Z",
          "iopub.status.idle": "2025-10-23T12:36:40.491301Z",
          "shell.execute_reply.started": "2025-10-23T12:36:40.021909Z",
          "shell.execute_reply": "2025-10-23T12:36:40.490395Z"
        },
        "id": "184UI3OoTbsj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "PRETR = 'bert-base-uncased'\n",
        "#PRETR = 'microsoft/deberta-base'\n",
        "#PRETR = \"SpanBERT/spanbert-base-cased\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-23T12:36:40.492655Z",
          "iopub.execute_input": "2025-10-23T12:36:40.492986Z",
          "iopub.status.idle": "2025-10-23T12:36:40.496503Z",
          "shell.execute_reply.started": "2025-10-23T12:36:40.492954Z",
          "shell.execute_reply": "2025-10-23T12:36:40.495777Z"
        },
        "id": "1ZELODM3Tbsk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "de = json.load(open(\"/kaggle/input/ade-dataset/drug_effect.json\"))\n",
        "de2 = []\n",
        "for document in tqdm(de['dataset_documents']):\n",
        "    markup = {'markup_spans': []}\n",
        "    reprs = set()\n",
        "    for element in document['document_markups'][0]['markup_elements']:\n",
        "        for span in element['element_spans']:\n",
        "            r = repr([span['espan_begin'], span['espan_end']])\n",
        "            if r not in reprs:\n",
        "                markup['markup_spans'].append({\n",
        "                    'espan_begin': span['espan_begin'],\n",
        "                    'espan_end': span['espan_end'],\n",
        "                    'espan_tags': ['O']\n",
        "                })\n",
        "                reprs.add(r)\n",
        "    de2.append({\n",
        "        'document_text': document['document_text'],\n",
        "        'document_markups': [markup]\n",
        "    })"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-23T12:36:40.497340Z",
          "iopub.execute_input": "2025-10-23T12:36:40.497627Z",
          "iopub.status.idle": "2025-10-23T12:36:41.041581Z",
          "shell.execute_reply.started": "2025-10-23T12:36:40.497598Z",
          "shell.execute_reply": "2025-10-23T12:36:41.040642Z"
        },
        "colab": {
          "referenced_widgets": [
            "14b7af0ecf044570b90a423fe13fc1e1"
          ]
        },
        "id": "S12DbmZoTbsk",
        "outputId": "6cb8fd2c-25db-49be-a4af-a0f830025855"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/4271 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "14b7af0ecf044570b90a423fe13fc1e1"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dd = json.load(open(\"/kaggle/input/ade-dataset/drug_dosage.json\"))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-23T12:36:41.042648Z",
          "iopub.execute_input": "2025-10-23T12:36:41.043002Z",
          "iopub.status.idle": "2025-10-23T12:36:41.061491Z",
          "shell.execute_reply.started": "2025-10-23T12:36:41.042970Z",
          "shell.execute_reply": "2025-10-23T12:36:41.060735Z"
        },
        "id": "yw0e1H3HTbsl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dd2 = []\n",
        "for document in tqdm(dd['dataset_documents']):\n",
        "    markup = {'markup_spans': []}\n",
        "    reprs = set()\n",
        "    for element in document['document_markups'][0]['markup_elements']:\n",
        "        for span in element['element_spans']:\n",
        "            r = repr([span['espan_begin'], span['espan_end']])\n",
        "            if r not in reprs:\n",
        "                markup['markup_spans'].append({\n",
        "                    'espan_begin': span['espan_begin'],\n",
        "                    'espan_end': span['espan_end'],\n",
        "                    'espan_tags': ['O']\n",
        "                })\n",
        "                reprs.add(r)\n",
        "    dd2.append({\n",
        "        'document_text': document['document_text'],\n",
        "        'document_markups': [markup]\n",
        "    })"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-23T12:36:41.062292Z",
          "iopub.execute_input": "2025-10-23T12:36:41.062563Z",
          "iopub.status.idle": "2025-10-23T12:36:41.083220Z",
          "shell.execute_reply.started": "2025-10-23T12:36:41.062530Z",
          "shell.execute_reply": "2025-10-23T12:36:41.082218Z"
        },
        "colab": {
          "referenced_widgets": [
            "33443af9689c493eaccd5ab480a589cf"
          ]
        },
        "id": "iOo4rQLaTbsm",
        "outputId": "85647558-1d01-43e7-efd0-e7b7a46b5f04"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/213 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "33443af9689c493eaccd5ab480a589cf"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = json.load(open(\"/kaggle/input/kaggle-ner-span-level-2/dataset.json\"))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-23T12:36:41.085563Z",
          "iopub.execute_input": "2025-10-23T12:36:41.085849Z",
          "iopub.status.idle": "2025-10-23T12:36:41.820427Z",
          "shell.execute_reply.started": "2025-10-23T12:36:41.085827Z",
          "shell.execute_reply": "2025-10-23T12:36:41.819447Z"
        },
        "id": "_LjfksJ0Tbsn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tags = set()\n",
        "for i in range(len(dataset[\"dataset_documents\"])):\n",
        "    spans = {}\n",
        "    for j, markup in enumerate(dataset[\"dataset_documents\"][i][\"document_markups\"]):\n",
        "        for span in markup[\"markup_spans\"]:\n",
        "            begin = span['espan_begin']\n",
        "            end = span['espan_end']\n",
        "            tag = span['espan_tags'][0]\n",
        "            tags.add(tag)\n",
        "            r = repr([begin, end])\n",
        "            if r not in spans:\n",
        "                spans[r] = {\n",
        "                    \"espan_begin\": begin,\n",
        "                    \"espan_end\": end,\n",
        "                    \"espan_tags\": ['O'] * j\n",
        "                }\n",
        "            spans[r][\"espan_tags\"].append(tag)\n",
        "        for r in spans:\n",
        "            if len(spans[r]['espan_tags']) == j:\n",
        "                spans[r]['espan_tags'].append('O')\n",
        "    dataset[\"dataset_documents\"][i] = {\n",
        "        \"document_text\": dataset[\"dataset_documents\"][i][\"document_text\"],\n",
        "        \"document_markups\": {\n",
        "            \"markup_spans\": list(spans.values())\n",
        "        }\n",
        "    }\n",
        "documents = dataset['dataset_documents']"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-08T16:46:52.576906Z",
          "iopub.execute_input": "2025-09-08T16:46:52.577198Z",
          "iopub.status.idle": "2025-09-08T16:46:52.808744Z",
          "shell.execute_reply.started": "2025-09-08T16:46:52.577177Z",
          "shell.execute_reply": "2025-09-08T16:46:52.808067Z"
        },
        "id": "RK3GhoOfTbsp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def ma_dataset(documents, tokenizer):\n",
        "    input_ids, token_type_ids, attention_mask, offset_mapping = tokenizer([document['document_text'] for document in documents],\n",
        "                                                                           return_offsets_mapping=True, truncation=True,\n",
        "                                                                           max_length=512, padding='max_length').values()\n",
        "    new_documents = datasets.Dataset.from_list([{\n",
        "        \"text\": documents[i][\"document_text\"],\n",
        "        \"input_ids\": input_ids[i],\n",
        "        \"attention_mask\": attention_mask[i],\n",
        "        \"offset_mapping\": offset_mapping[i],\n",
        "        \"markups\": documents[i]['document_markups'],\n",
        "        \"special_ids\": tokenizer.all_special_ids\n",
        "    } for i in range(len(documents))])\n",
        "    return new_documents.map(\n",
        "        function=ma_align_tokens,\n",
        "        input_columns=[\"text\", \"input_ids\", \"attention_mask\", \"offset_mapping\", \"markups\", \"special_ids\"]\n",
        "    )"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-23T12:36:41.821842Z",
          "iopub.execute_input": "2025-10-23T12:36:41.822238Z",
          "iopub.status.idle": "2025-10-23T12:36:41.827493Z",
          "shell.execute_reply.started": "2025-10-23T12:36:41.822215Z",
          "shell.execute_reply": "2025-10-23T12:36:41.826645Z"
        },
        "id": "fNL9ZueqTbsq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def ma_align_tokens(text, input_ids, attention_mask, offset_mapping, markups, special_ids):\n",
        "    new_markups = []\n",
        "    for markup in markups:\n",
        "        new_spans = []\n",
        "        for span in markup['markup_spans']:\n",
        "            begin = span['espan_begin']\n",
        "            end = span['espan_end']\n",
        "            tags = span['espan_tags']\n",
        "            new_begin = None\n",
        "            new_end = None\n",
        "            for j, token_id in enumerate(input_ids):\n",
        "                token_begin, token_end = offset_mapping[j]\n",
        "                if token_begin >= end:\n",
        "                    break\n",
        "                elif token_id in special_ids:\n",
        "                    continue\n",
        "                elif token_end > begin:\n",
        "                  if new_begin is None:\n",
        "                    new_begin = j\n",
        "                  new_end = j\n",
        "            assert new_begin is not None and new_end is not None\n",
        "            new_spans.append({\n",
        "                \"begin\": new_begin,\n",
        "                \"end\": new_end + 1,\n",
        "                \"tags\": tags\n",
        "            })\n",
        "        new_markups.append({\n",
        "            \"markup_spans\": new_spans\n",
        "        })\n",
        "    return {\n",
        "        \"text\": text,\n",
        "        \"input_ids\": input_ids,\n",
        "        \"attention_mask\": attention_mask,\n",
        "        \"markups\": new_markups\n",
        "    }"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-23T12:36:41.828213Z",
          "iopub.execute_input": "2025-10-23T12:36:41.828479Z",
          "iopub.status.idle": "2025-10-23T12:36:41.842271Z",
          "shell.execute_reply.started": "2025-10-23T12:36:41.828450Z",
          "shell.execute_reply": "2025-10-23T12:36:41.841478Z"
        },
        "id": "QP9Deb7lTbsq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(PRETR)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-23T12:36:41.843019Z",
          "iopub.execute_input": "2025-10-23T12:36:41.843244Z",
          "iopub.status.idle": "2025-10-23T12:36:44.918846Z",
          "shell.execute_reply.started": "2025-10-23T12:36:41.843226Z",
          "shell.execute_reply": "2025-10-23T12:36:44.918028Z"
        },
        "colab": {
          "referenced_widgets": [
            "7edd321ce6c04c3ab8cf8a6b60c87cc8",
            "e374086aeee4471c81380e2de3d6ad17",
            "7c67bfa224564738a8e5b637ff05ceb0",
            "aaef320b625d46aba5ac50be90f70025"
          ]
        },
        "id": "fUGBPxHwTbss",
        "outputId": "6f500c54-09fb-4dad-be0a-511bd95881f3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7edd321ce6c04c3ab8cf8a6b60c87cc8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e374086aeee4471c81380e2de3d6ad17"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7c67bfa224564738a8e5b637ff05ceb0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aaef320b625d46aba5ac50be90f70025"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dd = ma_dataset(dd2, tokenizer)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-23T12:36:44.919640Z",
          "iopub.execute_input": "2025-10-23T12:36:44.919896Z",
          "iopub.status.idle": "2025-10-23T12:36:45.574481Z",
          "shell.execute_reply.started": "2025-10-23T12:36:44.919875Z",
          "shell.execute_reply": "2025-10-23T12:36:45.573465Z"
        },
        "colab": {
          "referenced_widgets": [
            "ff8618117bc6407e99a65ace44c00b49"
          ]
        },
        "id": "C8pWHXeXTbss",
        "outputId": "a363d4da-9238-4e47-8e63-0004fc50e559"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/213 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ff8618117bc6407e99a65ace44c00b49"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dd = tokenized_dd.remove_columns(['offset_mapping', 'special_ids'])\n",
        "tokenized_dd"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-23T12:36:45.575442Z",
          "iopub.execute_input": "2025-10-23T12:36:45.575766Z",
          "iopub.status.idle": "2025-10-23T12:36:45.582479Z",
          "shell.execute_reply.started": "2025-10-23T12:36:45.575729Z",
          "shell.execute_reply": "2025-10-23T12:36:45.581643Z"
        },
        "id": "DvcMQcqUTbst",
        "outputId": "73cb0921-383a-4bbb-f25f-1097f6ee1a96"
      },
      "outputs": [
        {
          "execution_count": 13,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Dataset({\n    features: ['text', 'input_ids', 'attention_mask', 'markups'],\n    num_rows: 213\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_de = ma_dataset(de2, tokenizer)\n",
        "tokenized_de = tokenized_de.remove_columns(['offset_mapping', 'special_ids'])\n",
        "tokenized_de"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-23T12:36:45.583471Z",
          "iopub.execute_input": "2025-10-23T12:36:45.583770Z",
          "iopub.status.idle": "2025-10-23T12:36:58.658311Z",
          "shell.execute_reply.started": "2025-10-23T12:36:45.583745Z",
          "shell.execute_reply": "2025-10-23T12:36:58.657553Z"
        },
        "colab": {
          "referenced_widgets": [
            "2ec330e73043433981708a1c48417aca"
          ]
        },
        "id": "QTECfvUnTbst",
        "outputId": "87ae1d0a-6eff-471c-8da9-091e8b9da10b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/4271 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ec330e73043433981708a1c48417aca"
            }
          },
          "metadata": {}
        },
        {
          "execution_count": 14,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Dataset({\n    features: ['text', 'input_ids', 'attention_mask', 'markups'],\n    num_rows: 4271\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_docs = ma_dataset(dataset['dataset_documents'], tokenizer)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-23T12:36:58.659168Z",
          "iopub.execute_input": "2025-10-23T12:36:58.659488Z",
          "iopub.status.idle": "2025-10-23T12:39:20.124712Z",
          "shell.execute_reply.started": "2025-10-23T12:36:58.659455Z",
          "shell.execute_reply": "2025-10-23T12:39:20.123532Z"
        },
        "colab": {
          "referenced_widgets": [
            "7fcf36b2dffd4d17abe9aba72727d8e3"
          ]
        },
        "id": "prjzLWUGTbsu",
        "outputId": "e67dc308-3d77-445b-bd7a-b1f4c07b9c64"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/47575 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7fcf36b2dffd4d17abe9aba72727d8e3"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_docs = tokenized_docs.remove_columns(['offset_mapping', 'special_ids'])\n",
        "tokenized_docs"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-23T12:39:20.127003Z",
          "iopub.execute_input": "2025-10-23T12:39:20.127245Z",
          "iopub.status.idle": "2025-10-23T12:39:20.135011Z",
          "shell.execute_reply.started": "2025-10-23T12:39:20.127225Z",
          "shell.execute_reply": "2025-10-23T12:39:20.134174Z"
        },
        "id": "rGvOBFslTbsu",
        "outputId": "088c2d92-80c6-433e-9732-21dfb8879468"
      },
      "outputs": [
        {
          "execution_count": 16,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Dataset({\n    features: ['text', 'input_ids', 'attention_mask', 'markups'],\n    num_rows: 47575\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def ma(text, input_ids, attention_mask, markups):\n",
        "    clusters = []\n",
        "    for markup in markups:\n",
        "        for span in markup['markup_spans']:\n",
        "            flag = False\n",
        "            for j, cl in enumerate(clusters):\n",
        "                cur_span = cl[0]\n",
        "                if not cur_span['end'] <= span['begin'] and not span['end'] <= cur_span['begin']:\n",
        "                    union = max(cur_span['end'], span['end']) - min(cur_span['begin'], span['begin'])\n",
        "                    inter = min(cur_span['end'], span['end']) - max(cur_span['begin'], span['begin'])\n",
        "                    if inter / union >= 0.7:\n",
        "                        clusters[j].append(span)\n",
        "                        flag = True\n",
        "                        break\n",
        "            if not flag:\n",
        "                clusters.append([span])\n",
        "    new_spans = []\n",
        "    for cl in clusters:\n",
        "        sp_tags = defaultdict(list)\n",
        "        for span in cl:\n",
        "            sp_tags[span['tags'][0]].append(span)\n",
        "        for tag, spans in sp_tags.items():\n",
        "            begin = floor(sum([span['begin'] for span in spans]) / len(spans))\n",
        "            end = ceil(sum([span['end'] for span in spans]) / len(spans))\n",
        "            score = len(spans) / len(markups)\n",
        "            new_spans.append({'begin': begin, 'end': end, 'tags': [tag], 'score': score})\n",
        "    return {\n",
        "        \"text\": text,\n",
        "        \"input_ids\": input_ids,\n",
        "        \"attention_mask\": attention_mask,\n",
        "        \"spans\": new_spans\n",
        "    }"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-23T12:39:20.135966Z",
          "iopub.execute_input": "2025-10-23T12:39:20.136261Z",
          "iopub.status.idle": "2025-10-23T12:39:20.148929Z",
          "shell.execute_reply.started": "2025-10-23T12:39:20.136240Z",
          "shell.execute_reply": "2025-10-23T12:39:20.148090Z"
        },
        "id": "0vSUGk7BTbsu"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "ma_de = tokenized_de.map(function=ma, input_columns=['text', 'input_ids', 'attention_mask', 'markups'])\n",
        "ma_de = ma_de.remove_columns('markups')\n",
        "ma_de"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-23T12:39:20.149766Z",
          "iopub.execute_input": "2025-10-23T12:39:20.149977Z",
          "iopub.status.idle": "2025-10-23T12:39:23.724710Z",
          "shell.execute_reply.started": "2025-10-23T12:39:20.149959Z",
          "shell.execute_reply": "2025-10-23T12:39:23.724047Z"
        },
        "colab": {
          "referenced_widgets": [
            "89a5824cccee476ebc15945ef5229b2e"
          ]
        },
        "id": "paFDXAAjTbsu",
        "outputId": "c4feee85-7054-4571-aeaa-5f5dd90f646c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/4271 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "89a5824cccee476ebc15945ef5229b2e"
            }
          },
          "metadata": {}
        },
        {
          "execution_count": 18,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Dataset({\n    features: ['text', 'input_ids', 'attention_mask', 'spans'],\n    num_rows: 4271\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "ma_dd = tokenized_dd.map(function=ma, input_columns=['text', 'input_ids', 'attention_mask', 'markups'])\n",
        "ma_dd = ma_dd.remove_columns('markups')\n",
        "ma_dd"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-23T12:39:23.725570Z",
          "iopub.execute_input": "2025-10-23T12:39:23.725838Z",
          "iopub.status.idle": "2025-10-23T12:39:23.901268Z",
          "shell.execute_reply.started": "2025-10-23T12:39:23.725815Z",
          "shell.execute_reply": "2025-10-23T12:39:23.900338Z"
        },
        "colab": {
          "referenced_widgets": [
            "c20dabbc025747e6b7e4f0f53a4dd8d9"
          ]
        },
        "id": "KcChiM4PTbsv",
        "outputId": "e979102a-bd6f-40a2-ef4d-fbce7a4c0b58"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/213 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c20dabbc025747e6b7e4f0f53a4dd8d9"
            }
          },
          "metadata": {}
        },
        {
          "execution_count": 19,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Dataset({\n    features: ['text', 'input_ids', 'attention_mask', 'spans'],\n    num_rows: 213\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "ma_docs = tokenized_docs.map(function=ma, input_columns=['text', 'input_ids', 'attention_mask', 'markups'])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-23T12:39:23.902159Z",
          "iopub.execute_input": "2025-10-23T12:39:23.902415Z",
          "iopub.status.idle": "2025-10-23T12:39:57.195035Z",
          "shell.execute_reply.started": "2025-10-23T12:39:23.902393Z",
          "shell.execute_reply": "2025-10-23T12:39:57.194182Z"
        },
        "colab": {
          "referenced_widgets": [
            "a134099e47464c59b704cb2f70736b62"
          ]
        },
        "id": "aU8Kski9Tbsw",
        "outputId": "5d1c2701-e894-4087-946d-2db698a8ec4b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/47575 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a134099e47464c59b704cb2f70736b62"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "ma_docs = ma_docs.remove_columns('markups')\n",
        "ma_docs"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-23T12:39:57.195912Z",
          "iopub.execute_input": "2025-10-23T12:39:57.196370Z",
          "iopub.status.idle": "2025-10-23T12:39:57.203806Z",
          "shell.execute_reply.started": "2025-10-23T12:39:57.196334Z",
          "shell.execute_reply": "2025-10-23T12:39:57.203032Z"
        },
        "id": "afAbykzQTbsw",
        "outputId": "d6ed34da-d7df-4d8b-a570-ad5b84beb6d4"
      },
      "outputs": [
        {
          "execution_count": 21,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Dataset({\n    features: ['text', 'input_ids', 'attention_mask', 'spans'],\n    num_rows: 47575\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "res = ma_docs"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-23T12:39:57.204662Z",
          "iopub.execute_input": "2025-10-23T12:39:57.204989Z",
          "iopub.status.idle": "2025-10-23T12:39:57.215831Z",
          "shell.execute_reply.started": "2025-10-23T12:39:57.204968Z",
          "shell.execute_reply": "2025-10-23T12:39:57.215109Z"
        },
        "id": "KXX7-j6STbsw"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "res = res.train_test_split(test_size=0.9, shuffle=True, seed=42)\n",
        "res"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-23T12:41:54.162419Z",
          "iopub.execute_input": "2025-10-23T12:41:54.162815Z",
          "iopub.status.idle": "2025-10-23T12:41:54.185440Z",
          "shell.execute_reply.started": "2025-10-23T12:41:54.162783Z",
          "shell.execute_reply": "2025-10-23T12:41:54.184554Z"
        },
        "id": "f6rKvaH6Tbs0",
        "outputId": "8a31058e-bdee-4197-f335-e74b1a1b89f7"
      },
      "outputs": [
        {
          "execution_count": 23,
          "output_type": "execute_result",
          "data": {
            "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['text', 'input_ids', 'attention_mask', 'spans'],\n        num_rows: 4757\n    })\n    test: Dataset({\n        features: ['text', 'input_ids', 'attention_mask', 'spans'],\n        num_rows: 42818\n    })\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "lens = defaultdict(int)\n",
        "tags = set('O')\n",
        "for d in tqdm(res['train']):\n",
        "    for span in d['spans']:\n",
        "        length = span['end'] - span['begin']\n",
        "        lens[length] += 1\n",
        "        tags.add(span['tags'][0])\n",
        "tags = sorted(list(tags))\n",
        "lens, tags"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-23T12:41:54.587354Z",
          "iopub.execute_input": "2025-10-23T12:41:54.587722Z",
          "iopub.status.idle": "2025-10-23T12:41:57.277561Z",
          "shell.execute_reply.started": "2025-10-23T12:41:54.587658Z",
          "shell.execute_reply": "2025-10-23T12:41:57.276566Z"
        },
        "colab": {
          "referenced_widgets": [
            "70e6c19c05374f479f1cf9058767a39d"
          ]
        },
        "id": "O5RhPf5qTbs0",
        "outputId": "6bc5c978-2b11-4dea-f0b2-6663de6510ff"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/4757 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "70e6c19c05374f479f1cf9058767a39d"
            }
          },
          "metadata": {}
        },
        {
          "execution_count": 24,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(defaultdict(int,\n             {4: 1021,\n              1: 6069,\n              2: 2086,\n              6: 200,\n              3: 1051,\n              5: 377,\n              7: 115,\n              10: 9,\n              8: 58,\n              9: 26,\n              11: 6,\n              12: 5}),\n ['O', 'art', 'eve', 'geo', 'gpe', 'nat', 'org', 'per', 'tim'])"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class MAUniversalDataset(Dataset):\n",
        "    def __init__(self, documents, tags, lens, neg_num, mode, noise=None):\n",
        "        self.seed = -1\n",
        "        self.tags = tags\n",
        "        self.lens = lens\n",
        "        self.data = []\n",
        "        self.reprs = []\n",
        "        self.lengths = []\n",
        "        self.extras = []\n",
        "        for doc_id, document in enumerate(tqdm(documents)):\n",
        "            doc = []\n",
        "            reprs = set()\n",
        "            self.lengths.append(sum(document['attention_mask']) - 2)\n",
        "            for span in document['spans']:\n",
        "                begin, end = span['begin'], span['end']\n",
        "                span_tag = tags.index(span['tags'][0])\n",
        "                r = repr([begin, end])\n",
        "                if span['score'] >= 0.0:\n",
        "                    doc.append({\n",
        "                        \"text\": document['text'],\n",
        "                        \"input_ids\": document['input_ids'],\n",
        "                        \"attention_mask\": document['attention_mask'],\n",
        "                        \"begin\": begin,\n",
        "                        \"end\": end,\n",
        "                        \"y\": span_tag,\n",
        "                        'score': span['score']\n",
        "                    })\n",
        "                    reprs.add(r)\n",
        "                else:\n",
        "                    self.extras.append({\n",
        "                        \"text\": document['text'],\n",
        "                        \"input_ids\": document['input_ids'],\n",
        "                        \"attention_mask\": document['attention_mask'],\n",
        "                        \"begin\": begin,\n",
        "                        \"end\": end,\n",
        "                        \"y\": span_tag,\n",
        "                        'score': span['score']\n",
        "                    })\n",
        "            if mode == 'train':\n",
        "                for _ in range(neg_num):\n",
        "                    self.data.append({\n",
        "                        \"doc_id\": doc_id,\n",
        "                        \"text\": document['text'],\n",
        "                        \"input_ids\": document['input_ids'],\n",
        "                        \"attention_mask\": document['attention_mask'],\n",
        "                        \"begin\": None,\n",
        "                        \"end\": None,\n",
        "                        \"y\": None,\n",
        "                        'score': 1.0\n",
        "                    })\n",
        "            else:\n",
        "                neg_created = 0\n",
        "                attempts = 0\n",
        "                while neg_created < neg_num:\n",
        "                    attempts += 1\n",
        "                    sample = self.negative_sampler({\n",
        "                        \"doc_id\": doc_id,\n",
        "                        \"text\": document['text'],\n",
        "                        \"input_ids\": document['input_ids'],\n",
        "                        \"attention_mask\": document['attention_mask'],\n",
        "                        \"begin\": None,\n",
        "                        \"end\": None,\n",
        "                        \"y\": None,\n",
        "                        'score': 1\n",
        "                    }, reprs, self.lengths[doc_id])\n",
        "                    r = repr([sample['begin'], sample['end']])\n",
        "                    reprs.add(r)\n",
        "                    neg_created += 1\n",
        "                    self.data.append(sample)\n",
        "            self.data += doc\n",
        "            self.reprs.append(reprs)\n",
        "        if noise is not None:\n",
        "            for j in range(len(self.data)):\n",
        "                self.data[j]['noise'] = np.random.default_rng(j).normal(loc=0, scale=noise['scale'], size=noise['size']).tolist()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    def __getitem__(self, index):\n",
        "        el = self.data[index]\n",
        "        if el['begin'] is None:\n",
        "            doc_id = el['doc_id']\n",
        "            el = self.negative_sampler(el, self.reprs[doc_id], self.lengths[doc_id])\n",
        "        return el\n",
        "    def negative_sampler(self, el, reprs, full_length):\n",
        "        self.seed += 1\n",
        "        while True:\n",
        "            rng = np.random.default_rng(self.seed)\n",
        "            length = rng.choice(list(map(int, self.lens.keys())), 1, p=np.array(list(self.lens.values())) / np.array(list(self.lens.values())).sum())[0]\n",
        "            begin = rng.choice(np.arange(1, max(full_length - length, 2)), 1)[0]\n",
        "            end = min(begin + length, full_length + 1)\n",
        "            try:\n",
        "                assert begin < end\n",
        "            except:\n",
        "                print(begin, end, length, full_length)\n",
        "                assert False\n",
        "            r = repr([begin, end])\n",
        "            flag = True\n",
        "            for rep in reprs:\n",
        "                cur_begin, cur_end = rep[1:-1].split(', ')\n",
        "                cur_begin, cur_end = int(cur_begin), int(cur_end)\n",
        "                if cur_begin >= end or begin >= cur_end:\n",
        "                    continue\n",
        "                union = max(end, cur_end) - min(begin, cur_begin)\n",
        "                inter = min(end, cur_end) - max(begin, cur_begin)\n",
        "                if inter / union >= 0.7:\n",
        "                    flag = False\n",
        "                    break\n",
        "            if flag:\n",
        "                break\n",
        "            self.seed += 1\n",
        "        return {\n",
        "            \"text\": el['text'],\n",
        "            \"input_ids\": el['input_ids'],\n",
        "            \"attention_mask\": el['attention_mask'],\n",
        "            \"begin\": begin,\n",
        "            \"end\": end,\n",
        "            \"y\": self.tags.index('O'),\n",
        "            'score': 1\n",
        "        }"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-23T12:41:57.278728Z",
          "iopub.execute_input": "2025-10-23T12:41:57.278960Z",
          "iopub.status.idle": "2025-10-23T12:41:57.293390Z",
          "shell.execute_reply.started": "2025-10-23T12:41:57.278937Z",
          "shell.execute_reply": "2025-10-23T12:41:57.292513Z"
        },
        "id": "PkFcoeZ0Tbs1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = MAUniversalDataset(res['train'], tags, lens, 1, mode='train')\n",
        "eval_dataset = MAUniversalDataset(res['test'].select(range(2000)), tags, lens, 1, mode='test')\n",
        "noise_dataset = MAUniversalDataset(res['test'].select(range(2000)), tags, lens, 0, mode='test', noise={'scale': 0.01, 'size': 768})\n",
        "dd_dataset = MAUniversalDataset(ma_dd, tags, lens, 0, mode='test')\n",
        "de_dataset = MAUniversalDataset(ma_de, tags, lens, 0, mode='test')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-23T12:41:57.294826Z",
          "iopub.execute_input": "2025-10-23T12:41:57.295073Z",
          "iopub.status.idle": "2025-10-23T12:42:05.347686Z",
          "shell.execute_reply.started": "2025-10-23T12:41:57.295053Z",
          "shell.execute_reply": "2025-10-23T12:42:05.346655Z"
        },
        "colab": {
          "referenced_widgets": [
            "50e9af46602b4269b0cf6710c2167a39",
            "9ba5320c1a97494e9367ef616bd6b75d",
            "15f309379b934d1f999ce10e404fe295",
            "c3df5eccaad848829449e0e765fe9f43",
            "c403d3d735954281b05d1bf9169df0ec"
          ]
        },
        "id": "owAj7QItTbs2",
        "outputId": "dad1cbf8-c048-4919-f8c5-a6b888aee99c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/4757 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "50e9af46602b4269b0cf6710c2167a39"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/2000 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ba5320c1a97494e9367ef616bd6b75d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/2000 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "15f309379b934d1f999ce10e404fe295"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/213 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c3df5eccaad848829449e0e765fe9f43"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/4271 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c403d3d735954281b05d1bf9169df0ec"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    batch_input_ids = []\n",
        "    batch_attention_mask = []\n",
        "    batch_begin = []\n",
        "    batch_end = []\n",
        "    batch_y = []\n",
        "    batch_score = []\n",
        "    flag = 'noise' in batch[0]\n",
        "    if flag:\n",
        "        batch_noise = []\n",
        "    for el in batch:\n",
        "        batch_input_ids.append(el['input_ids'])\n",
        "        batch_attention_mask.append(el['attention_mask'])\n",
        "        batch_begin.append(el['begin'])\n",
        "        batch_end.append(el['end'])\n",
        "        batch_score.append(el['score'])\n",
        "        if flag:\n",
        "            batch_noise.append(el['noise'])\n",
        "        batch_y.append(el['y'])\n",
        "    batch_input_ids = torch.tensor(batch_input_ids, dtype=torch.long)\n",
        "    batch_attention_mask = torch.tensor(batch_attention_mask, dtype=torch.long)\n",
        "    batch_begin = torch.tensor(batch_begin, dtype=torch.long)\n",
        "    batch_end = torch.tensor(batch_end, dtype=torch.long)\n",
        "    batch_score = torch.tensor(batch_score)\n",
        "    batch_y = torch.tensor(batch_y)\n",
        "    res = {\n",
        "        \"input_ids\": batch_input_ids,\n",
        "        \"attention_mask\": batch_attention_mask,\n",
        "        \"begin\": batch_begin,\n",
        "        \"end\": batch_end,\n",
        "        \"y\": batch_y,\n",
        "        'score': batch_score\n",
        "    }\n",
        "    if flag:\n",
        "        res['noise'] = torch.tensor(batch_noise)\n",
        "    return res"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-23T12:42:22.749020Z",
          "iopub.execute_input": "2025-10-23T12:42:22.749398Z",
          "iopub.status.idle": "2025-10-23T12:42:22.756983Z",
          "shell.execute_reply.started": "2025-10-23T12:42:22.749365Z",
          "shell.execute_reply": "2025-10-23T12:42:22.755870Z"
        },
        "id": "4mw1mLT0Tbs7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class UniversalModel(nn.Module):\n",
        "    def __init__(self, embedder, tokenizer, hidden_size, num_classes, aggr, device):\n",
        "        super().__init__()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.embedder = embedder.to(device)\n",
        "        self.num_classes = num_classes\n",
        "        self.aggr = aggr\n",
        "        self.hidden_size = hidden_size\n",
        "        if self.aggr == 'attn':\n",
        "            self.v = nn.Linear(self.hidden_size, 1)\n",
        "            self.flat = nn.Flatten()\n",
        "            self.softmax = nn.Softmax(dim=1)\n",
        "        elif self.aggr == 'endpoint' or self.aggr == 'diff-sum':\n",
        "            self.hidden_size *= 2\n",
        "        elif self.aggr == 'coherent':\n",
        "            self.a = 15 * self.hidden_size // 32\n",
        "            self.b = self.hidden_size // 32\n",
        "            self.hidden_size = 2 * self.a + 1\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(self.hidden_size, self.hidden_size),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(self.hidden_size, num_classes)\n",
        "        )\n",
        "        self.device = device\n",
        "    def span_embedder(self, embeddings, begin, end):\n",
        "        mask = torch.zeros(embeddings.shape[0], embeddings.shape[1]).bool().to(self.device)\n",
        "        poses = torch.arange(embeddings.shape[1]).to(self.device).reshape(1, embeddings.shape[1])\n",
        "        mask[(poses >= begin[:,None]) & (poses < end[:,None])] = True\n",
        "        if self.aggr == 'mean':\n",
        "            return (embeddings * mask[:,:,None]).sum(dim=1) / (end - begin)[:,None]\n",
        "        if self.aggr == 'attn':\n",
        "            alpha = self.flat(self.v(embeddings))\n",
        "            alpha[~mask] = float('-inf')\n",
        "            alpha = self.softmax(alpha)\n",
        "            return (embeddings * alpha[:,:,None]).sum(dim=1)\n",
        "        if self.aggr == 'max':\n",
        "            embeddings[~mask] = float('-inf')\n",
        "            span_embeddings = embeddings.max(dim=1).values\n",
        "            span_embeddings[begin >= end] = 0\n",
        "            return span_embeddings\n",
        "        if self.aggr == 'endpoint':\n",
        "            return torch.cat([embeddings[(torch.arange(embeddings.shape[0]), begin)],\n",
        "                              embeddings[(torch.arange(embeddings.shape[0]), end - 1)]], dim=1)\n",
        "        if self.aggr == 'diff-sum':\n",
        "            begin_emb = embeddings[(torch.arange(embeddings.shape[0]), begin)]\n",
        "            end_emb = embeddings[(torch.arange(embeddings.shape[0]), end - 1)]\n",
        "            return torch.cat([end_emb + begin_emb, end_emb - begin_emb], dim=1)\n",
        "        if self.aggr == 'coherent':\n",
        "            begin_emb = embeddings[(torch.arange(embeddings.shape[0]), begin)]\n",
        "            end_emb = embeddings[(torch.arange(embeddings.shape[0]), end - 1)]\n",
        "            return torch.cat([begin_emb[:,:self.a], end_emb[:,self.a:2 * self.a],\n",
        "                              (begin_emb[:,2 * self.a:2 * self.a + self.b] * end_emb[:,2 * self.a + self.b:]).sum(dim=1).reshape(-1, 1)], dim=1)\n",
        "        raise ValueError('wrong span aggregation name')\n",
        "    def forward(self, input_ids, attention_mask, begin, end, *args, **kwargs):\n",
        "        embeddings = self.embedder(input_ids.to(self.device), attention_mask.to(self.device))[0]\n",
        "        self.span_embeddings = self.span_embedder(embeddings, begin, end)\n",
        "        if kwargs['noise'] is not None:\n",
        "            self.span_embeddings = self.span_embeddings + kwargs['noise'].to(self.device)\n",
        "        if kwargs['retain']:\n",
        "            self.span_embeddings.retain_grad()\n",
        "        return self.fc(self.span_embeddings)\n",
        "    def get_activations_and_gradients(self):\n",
        "        return self.span_embeddings, self.span_embeddings_grad\n",
        "    def get_embeddings(self, input_ids, attention_mask, begin, end):\n",
        "        embeddings = self.embedder(input_ids.to(self.device), attention_mask.to(self.device))[0]\n",
        "        mask = torch.zeros(embeddings.shape[0], embeddings.shape[1]).to(self.device)\n",
        "        for i in range(begin.shape[0]):\n",
        "            mask[i, begin[i]:end[i]] = 1\n",
        "        return (embeddings * mask[:,:,None]).sum(dim=1) / (end.to(self.device) - begin.to(self.device))[:,None]\n",
        "    def predict_for_fixed_length(self, input_ids, attention_mask, fixed_len):\n",
        "        '''\n",
        "        For only one text!\n",
        "        '''\n",
        "        embeddings = self.embedder(input_ids, attention_mask)[0]\n",
        "        assert embeddings.shape[0] == 1\n",
        "        span_embeddings = embeddings[0, 1:(attention_mask.sum().item() - 1)].unfold(dimension=0, size=fixed_len, step=1).permute(0, 2, 1).mean(dim=1)\n",
        "        return self.fc(span_embeddings)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-23T12:42:22.960111Z",
          "iopub.execute_input": "2025-10-23T12:42:22.960442Z",
          "iopub.status.idle": "2025-10-23T12:42:22.976692Z",
          "shell.execute_reply.started": "2025-10-23T12:42:22.960414Z",
          "shell.execute_reply": "2025-10-23T12:42:22.975868Z"
        },
        "id": "og0G8MrjTbs7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class WarmupScheduler(_LRScheduler):\n",
        "    def __init__(self, optimizer, warmup_steps, total_steps, mode='linear', last_epoch=-1):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            optimizer: \n",
        "            warmup_steps:   \n",
        "            total_steps:   \n",
        "            mode: 'linear'  'cosine'\n",
        "        \"\"\"\n",
        "        self.warmup_steps = warmup_steps\n",
        "        self.total_steps = total_steps\n",
        "        self.mode = mode\n",
        "        super().__init__(optimizer, last_epoch)\n",
        "\n",
        "    def get_lr(self):\n",
        "        if self.last_epoch < self.warmup_steps:\n",
        "            #  \n",
        "            progress = self.last_epoch / self.warmup_steps\n",
        "            return [base_lr * progress for base_lr in self.base_lrs]\n",
        "        else:\n",
        "            #  \n",
        "            progress = (self.last_epoch - self.warmup_steps) / (self.total_steps - self.warmup_steps)\n",
        "            if self.mode == 'linear':\n",
        "                factor = max(0.0, 1.0 - progress)\n",
        "            elif self.mode == 'cosine':\n",
        "                factor = max(0.0, 0.5 * (1.0 + cos(pi * progress)))\n",
        "            return [base_lr * factor for base_lr in self.base_lrs]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-23T12:42:23.175519Z",
          "iopub.execute_input": "2025-10-23T12:42:23.175863Z",
          "iopub.status.idle": "2025-10-23T12:42:23.181882Z",
          "shell.execute_reply.started": "2025-10-23T12:42:23.175832Z",
          "shell.execute_reply": "2025-10-23T12:42:23.181031Z"
        },
        "id": "c38s54vgTbs8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def set_global_seed(seed: int) -> None:\n",
        "    \"\"\"Set global seed for reproducibility.\n",
        "    :param int seed: Seed to be set\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    #    1000% \n",
        "    # torch.use_deterministic_algorithms(False)\n",
        "\n",
        "    #  Dataloader\n",
        "    g = torch.Generator()\n",
        "    g.manual_seed(seed)\n",
        "\n",
        "    return g\n",
        "\n",
        "#   worker  Dataloader\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-23T12:42:28.770147Z",
          "iopub.execute_input": "2025-10-23T12:42:28.770446Z",
          "iopub.status.idle": "2025-10-23T12:42:28.775585Z",
          "shell.execute_reply.started": "2025-10-23T12:42:28.770424Z",
          "shell.execute_reply": "2025-10-23T12:42:28.774537Z"
        },
        "id": "cUcje2IRTbs8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def log_gradients(model, global_step, log_norm=True, log_hist=True):\n",
        "    for tag, value in model.named_parameters():\n",
        "        g = value.grad\n",
        "        if g is None:\n",
        "            continue\n",
        "\n",
        "        if log_hist:\n",
        "            wandb.log({f\"grad/{tag}\": wandb.Histogram(g.cpu())}, global_step)\n",
        "\n",
        "        if log_norm:\n",
        "            wandb.log({f\"grad_norm/{tag}\": torch.norm(g.cpu())}, global_step)\n",
        "\n",
        "@torch.no_grad()\n",
        "def log_weights(model, global_step, log_norm=True, log_hist=True):\n",
        "    for tag, value in model.named_parameters():\n",
        "        g = value.grad\n",
        "        if g is None:\n",
        "            continue\n",
        "\n",
        "        if log_hist:\n",
        "            wandb.log({f\"weight/{tag}\": wandb.Histogram(value.cpu())}, global_step)\n",
        "\n",
        "        if log_norm:\n",
        "            wandb.log({f\"weight_norm/{tag}\": torch.norm(value.cpu())}, global_step)\n",
        "\n",
        "@torch.no_grad()\n",
        "def vog(model):\n",
        "    res = []\n",
        "    for tag, value in model.named_parameters():\n",
        "        g = value.grad\n",
        "        if g is None:\n",
        "            continue\n",
        "        res.append(torch.norm(g.cpu()))\n",
        "    return res\n",
        "\n",
        "def get_activations(net, batch, loss_fn, optimizer):\n",
        "    optimizer.zero_grad()\n",
        "    input_ids = batch['input_ids'].to(device)\n",
        "    attention_mask = batch['attention_mask'].to(device)\n",
        "    begin = batch['begin'].to(device)\n",
        "    end = batch['end'].to(device)\n",
        "    y = batch['y'].to(device)\n",
        "    score = batch['score'].to(device)\n",
        "    out = net(input_ids, token_type_ids, attention_mask, begin, end, retain=True)\n",
        "    loss = torch.dot(loss_fn(out, y), score.to(out.dtype)) / score.sum()\n",
        "    loss.backward()\n",
        "    return net.span_embeddings.grad.detach().cpu().tolist()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-23T12:42:28.966612Z",
          "iopub.execute_input": "2025-10-23T12:42:28.966929Z",
          "iopub.status.idle": "2025-10-23T12:42:28.975485Z",
          "shell.execute_reply.started": "2025-10-23T12:42:28.966905Z",
          "shell.execute_reply": "2025-10-23T12:42:28.974654Z"
        },
        "id": "JCM2cb9lTbs9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "def evaluate(net, val_dataloader, loss_fn, optimizer, device):\n",
        "    net.eval()\n",
        "    val_grads = []\n",
        "    loss = 0\n",
        "    count = 0\n",
        "    trues = []\n",
        "    preds = []\n",
        "    scores = []\n",
        "    for batch in tqdm(val_dataloader, leave=False):\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        begin = batch['begin'].to(device)\n",
        "        end = batch['end'].to(device)\n",
        "        y = batch['y'].to(device)\n",
        "        score = batch['score'].to(device)\n",
        "        if 'noise' in batch:\n",
        "            noise = batch['noise']\n",
        "        else:\n",
        "            noise = None\n",
        "\n",
        "        out = net(input_ids, attention_mask, begin, end, retain=True, noise=noise)\n",
        "        loss_cur = torch.dot(loss_fn(out, y), score.to(out.dtype)) / score.sum()\n",
        "        loss += loss_cur.item() * score.sum().item()\n",
        "        trues += y.cpu().tolist()\n",
        "        preds += torch.argmax(out, dim=-1).cpu().tolist()\n",
        "        scores += score.cpu().tolist()\n",
        "        count += score.sum().item()\n",
        "        loss_cur.backward()\n",
        "        val_grads += net.span_embeddings.grad.detach().cpu().tolist()\n",
        "    accuracy = accuracy_score(trues, preds, sample_weight=scores)\n",
        "    precision_macro = precision_score(trues, preds, labels=range(net.num_classes), sample_weight=scores, average='macro', zero_division=0)\n",
        "    precision_micro = precision_score(trues, preds, labels=range(net.num_classes), sample_weight=scores, average='micro', zero_division=0)\n",
        "    recall_macro = recall_score(trues, preds, labels=range(net.num_classes), sample_weight=scores, average='macro', zero_division=0)\n",
        "    recall_micro = recall_score(trues, preds, labels=range(net.num_classes), sample_weight=scores, average='micro', zero_division=0)\n",
        "    f1_macro = f1_score(trues, preds, labels=range(net.num_classes), sample_weight=scores, average='macro', zero_division=0)\n",
        "    f1_micro = f1_score(trues, preds, labels=range(net.num_classes), sample_weight=scores, average='micro', zero_division=0)\n",
        "\n",
        "    return loss / count, accuracy, precision_macro, precision_micro, recall_macro, recall_micro, f1_macro, f1_micro, val_grads"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-23T12:42:29.217800Z",
          "iopub.execute_input": "2025-10-23T12:42:29.218121Z",
          "iopub.status.idle": "2025-10-23T12:42:29.227497Z",
          "shell.execute_reply.started": "2025-10-23T12:42:29.218096Z",
          "shell.execute_reply": "2025-10-23T12:42:29.226492Z"
        },
        "id": "vKnSsC3tTbs9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "def train(config, net, optimizer, scheduler, loss_fn, train_dataloader, val_dataloader, other_loaders, device, log_iterations, max_grad_norm=1.0):\n",
        "\n",
        "\n",
        "    wandb.init(\n",
        "        project=\"universal\",\n",
        "        name=config['name'],\n",
        "        config=config\n",
        "    )\n",
        "\n",
        "    global_step = 0\n",
        "    net = net.to(device)\n",
        "\n",
        "    # \n",
        "    best_f1 = 0\n",
        "    os.makedirs(config['checkpoint_dir'], exist_ok=True)\n",
        "\n",
        "    epoch_num = config['epoch_num']\n",
        "    # train_grads = {}\n",
        "    val_grads = []\n",
        "    other_grads = {}\n",
        "    for name in other_loaders:\n",
        "        other_grads[name] = []\n",
        "    for epoch in tqdm(range(epoch_num)):\n",
        "        net.train()\n",
        "        #train_grads[epoch] = []\n",
        "\n",
        "        for batch in tqdm(train_dataloader, leave=False):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            begin = batch['begin'].to(device)\n",
        "            end = batch['end'].to(device)\n",
        "            y = batch['y'].to(device)\n",
        "            scores = batch['score'].to(device)\n",
        "\n",
        "            out = net(input_ids, attention_mask, begin, end, retain=False, noise=None)\n",
        "\n",
        "            loss = loss_fn(out, y)\n",
        "            loss = torch.dot(loss, scores.to(out.dtype)) / scores.sum()\n",
        "            loss.backward()\n",
        "            #train_grads[epoch] += net.span_embeddings.grad.detach().cpu().tolist()\n",
        "\n",
        "            torch.nn.utils.clip_grad_norm_(net.parameters(), max_grad_norm)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            #y_pred = torch.argmax(out, 1)\n",
        "            #accuracy = torch.sum(y_pred == y_true) / y_pred.shape[0]\n",
        "\n",
        "            if global_step % log_iterations == 0:\n",
        "                torch.cuda.empty_cache()\n",
        "                gc.collect()\n",
        "                log_gradients(net, global_step)\n",
        "                log_weights(net, global_step)\n",
        "                wandb.log({\"train/loss\": loss.item()}, step=global_step)\n",
        "\n",
        "                loss, accuracy, precision_macro, precision_micro, recall_macro, recall_micro, f1_macro, f1_micro, grads = evaluate(\n",
        "                    net              = net,\n",
        "                    val_dataloader   = val_dataloader,\n",
        "                    loss_fn          = loss_fn,\n",
        "                    optimizer        = optimizer,\n",
        "                    device           = device\n",
        "                )\n",
        "                val_grads.append(grads)\n",
        "                for name in other_loaders:\n",
        "                    res = evaluate(\n",
        "                        net              = net,\n",
        "                        val_dataloader   = other_loaders[name],\n",
        "                        loss_fn          = loss_fn,\n",
        "                        optimizer        = optimizer,\n",
        "                        device           = device\n",
        "                    )\n",
        "                    other_grads[name].append(res[-1])\n",
        "                wandb.log({\n",
        "                    \"eval/loss\": loss, 'eval/accuracy': accuracy,\n",
        "                    'eval/precision_macro': precision_macro, 'eval/precision_micro': precision_micro,\n",
        "                    'eval/recall_macro': recall_macro, 'eval/recall_micro': recall_micro,\n",
        "                    'eval/f1_macro': f1_macro, 'eval/f1_micro': f1_micro,\n",
        "                }, step=global_step)\n",
        "                f1 = (f1_macro + f1_micro) / 2\n",
        "\n",
        "                # \n",
        "                if f1 > best_f1:\n",
        "                    best_f1 = f1\n",
        "                    torch.save({\n",
        "                        'epoch': epoch,\n",
        "                        'iter': global_step,\n",
        "                        'model_state_dict': net.state_dict(),\n",
        "                        'optimizer_state_dict': optimizer.state_dict(),\n",
        "                        'f1': f1,\n",
        "                        }, os.path.join(config['checkpoint_dir'], config['checkpoint_name']))\n",
        "\n",
        "            global_step += 1\n",
        "        '''\n",
        "        val_grads[epoch] = []\n",
        "        for batch in tqdm(val_dataloader, leave=False):\n",
        "            val_grads[epoch] += get_activations(net, batch, loss_fn, optimizer)\n",
        "        '''\n",
        "    wandb.finish()\n",
        "    return val_grads, other_grads"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-23T12:42:29.436933Z",
          "iopub.execute_input": "2025-10-23T12:42:29.437259Z",
          "iopub.status.idle": "2025-10-23T12:42:29.448501Z",
          "shell.execute_reply.started": "2025-10-23T12:42:29.437233Z",
          "shell.execute_reply": "2025-10-23T12:42:29.447495Z"
        },
        "id": "TQ0yhvmATbs-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "aggr = 'mean'\n",
        "config = {\n",
        "    'seed'           : 42,\n",
        "    'lr'             : 1e-4,\n",
        "    'epoch_num'      : 2,\n",
        "    'batch_size'     : 16,\n",
        "    'val_batch_size' : 16,\n",
        "    'name'           : f'exp {PRETR} {aggr}',\n",
        "    'checkpoint_dir' : './checkpoints',\n",
        "    'checkpoint_name': 'MLP.pth',\n",
        "    'hidden_size'    : 768,\n",
        "    'num_classes'    : len(tags)\n",
        "}\n",
        "\n",
        "g = set_global_seed(config['seed'])\n",
        "g.manual_seed(0)\n",
        "\n",
        "device = 'cpu'\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = 'cuda:0'\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size     = config['batch_size'],\n",
        "    shuffle        = True,\n",
        "    drop_last      = True,\n",
        "    num_workers    = 3,\n",
        "    worker_init_fn = seed_worker,\n",
        "    generator      = g,\n",
        "    collate_fn     = collate_fn\n",
        ")\n",
        "\n",
        "val_dataloader = DataLoader(\n",
        "    eval_dataset,\n",
        "    batch_size     = config['val_batch_size'],\n",
        "    shuffle        = False,\n",
        "    drop_last      = False,\n",
        "    num_workers    = 0,\n",
        "    worker_init_fn = seed_worker,\n",
        "    generator      = g,\n",
        "    collate_fn     = collate_fn\n",
        ")\n",
        "other_loaders = {}\n",
        "other_loaders['noise'] = DataLoader(\n",
        "    noise_dataset,\n",
        "    batch_size     = config['val_batch_size'],\n",
        "    shuffle        = False,\n",
        "    drop_last      = False,\n",
        "    num_workers    = 0,\n",
        "    worker_init_fn = seed_worker,\n",
        "    generator      = g,\n",
        "    collate_fn     = collate_fn\n",
        ")\n",
        "\n",
        "other_loaders['drug_dosage'] = DataLoader(\n",
        "    dd_dataset,\n",
        "    batch_size     = config['val_batch_size'],\n",
        "    shuffle        = False,\n",
        "    drop_last      = False,\n",
        "    num_workers    = 0,\n",
        "    worker_init_fn = seed_worker,\n",
        "    generator      = g,\n",
        "    collate_fn     = collate_fn\n",
        ")\n",
        "\n",
        "other_loaders['drug_effect'] = DataLoader(\n",
        "    de_dataset,\n",
        "    batch_size     = config['val_batch_size'],\n",
        "    shuffle        = False,\n",
        "    drop_last      = False,\n",
        "    num_workers    = 0,\n",
        "    worker_init_fn = seed_worker,\n",
        "    generator      = g,\n",
        "    collate_fn     = collate_fn\n",
        ")\n",
        "\n",
        "# tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
        "embedder = AutoModel.from_pretrained(PRETR)\n",
        "net = UniversalModel(embedder, tokenizer, config['hidden_size'], config['num_classes'], aggr, device)\n",
        "net.to('cuda')\n",
        "optimizer = optim.AdamW(net.parameters(), lr=config['lr'])\n",
        "total_steps = config['epoch_num'] * len(train_dataloader)\n",
        "scheduler = WarmupScheduler(\n",
        "    optimizer,\n",
        "    warmup_steps=int(0.1 * total_steps),\n",
        "    total_steps=total_steps,\n",
        "    mode='cosine'\n",
        ")\n",
        "loss_fn = nn.CrossEntropyLoss(reduction='none')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-23T12:42:29.846598Z",
          "iopub.execute_input": "2025-10-23T12:42:29.846965Z",
          "iopub.status.idle": "2025-10-23T12:42:33.061411Z",
          "shell.execute_reply.started": "2025-10-23T12:42:29.846937Z",
          "shell.execute_reply": "2025-10-23T12:42:33.060690Z"
        },
        "colab": {
          "referenced_widgets": [
            "6710eedeb8314e9483b6c8f34c1c90ab"
          ]
        },
        "id": "p1CjzQqWTbs-",
        "outputId": "f6935012-3f73-4993-c470-f34b407d9f14"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6710eedeb8314e9483b6c8f34c1c90ab"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "val_grads, other_grads = train(config, net, optimizer, scheduler, loss_fn, train_dataloader, val_dataloader,\n",
        "                               other_loaders, device, log_iterations=300)"
      ],
      "metadata": {
        "trusted": true,
        "id": "9WWvPKFGTbs-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "other_grads['val'] = val_grads\n",
        "pickle.dump(other_grads, open('/kaggle/working/grads.pkl', 'wb'))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-21T18:58:56.792104Z",
          "iopub.execute_input": "2025-09-21T18:58:56.792431Z",
          "iopub.status.idle": "2025-09-21T18:59:06.058162Z",
          "shell.execute_reply.started": "2025-09-21T18:58:56.792407Z",
          "shell.execute_reply": "2025-09-21T18:59:06.057176Z"
        },
        "id": "Q_wH-3_7Tbs_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "kagglehub.model_upload(f'taband58/kaggle_universal/pyTorch/2b', '/kaggle/working/checkpoints/MLP.pth', 'Apache 2.0',\n",
        "                       version_notes=f\"{PRETR} {aggr}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-21T19:01:04.528169Z",
          "iopub.execute_input": "2025-09-21T19:01:04.528502Z",
          "iopub.status.idle": "2025-09-21T19:02:48.839508Z",
          "shell.execute_reply.started": "2025-09-21T19:01:04.528474Z",
          "shell.execute_reply": "2025-09-21T19:02:48.838729Z"
        },
        "id": "XljCdi5LTbtE",
        "outputId": "a1733ddf-bc8f-4afd-f7e0-30ec57020a48"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Uploading Model https://www.kaggle.com/models/taband58/kaggle_universal/pyTorch/2b ...\nWarning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.9), please consider upgrading to the latest version (0.3.13).\nStarting upload for file /kaggle/working/checkpoints/MLP.pth\nWarning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.9), please consider upgrading to the latest version (0.3.13).\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Uploading: 100%|| 1.32G/1.32G [01:01<00:00, 21.4MB/s]  ",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Upload successful: /kaggle/working/checkpoints/MLP.pth (1GB)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.9), please consider upgrading to the latest version (0.3.13).\nYour model instance version has been created.\nFiles are being processed...\nSee at: https://www.kaggle.com/models/taband58/kaggle_universal/pyTorch/2b\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "state_dict = torch.load(\"/kaggle/input/kaggle_universal/pytorch/2b/7/MLP.pth\", map_location='cuda')\n",
        "net.load_state_dict(state_dict['model_state_dict'])\n",
        "optimizer.load_state_dict(state_dict['optimizer_state_dict'])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-23T12:42:44.187294Z",
          "iopub.execute_input": "2025-10-23T12:42:44.187605Z",
          "iopub.status.idle": "2025-10-23T12:42:50.601444Z",
          "shell.execute_reply.started": "2025-10-23T12:42:44.187581Z",
          "shell.execute_reply": "2025-10-23T12:42:50.600752Z"
        },
        "id": "R2rAn3i4TbtE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "res = evaluate(net, val_dataloader, loss_fn, optimizer, 'cuda')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-05T19:37:08.200077Z",
          "iopub.execute_input": "2025-10-05T19:37:08.200424Z",
          "iopub.status.idle": "2025-10-05T19:42:47.292479Z",
          "shell.execute_reply.started": "2025-10-05T19:37:08.200398Z",
          "shell.execute_reply": "2025-10-05T19:42:47.291797Z"
        },
        "colab": {
          "referenced_widgets": [
            ""
          ]
        },
        "id": "2cseUYeRTbtE",
        "outputId": "91f0f069-daa4-46b2-dfdf-708622df5c7b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/413 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "res[:-1]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-05T19:42:49.222538Z",
          "iopub.execute_input": "2025-10-05T19:42:49.222892Z",
          "iopub.status.idle": "2025-10-05T19:42:49.228547Z",
          "shell.execute_reply.started": "2025-10-05T19:42:49.222865Z",
          "shell.execute_reply": "2025-10-05T19:42:49.227663Z"
        },
        "id": "WKW-BnAVTbtE",
        "outputId": "675f5ae0-a215-404e-92da-e8e94914812d"
      },
      "outputs": [
        {
          "execution_count": 37,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(0.2889057270376002,\n 0.9107746656566315,\n 0.7137675571560931,\n 0.9107746656566315,\n 0.6178072214371854,\n 0.9107746656566315,\n 0.6312116074921346,\n 0.9107746656566315)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def process_set(net0, loader):\n",
        "    embeddings = []\n",
        "    answers = []\n",
        "    y = []\n",
        "    score = []\n",
        "    begin = []\n",
        "    end = []\n",
        "    net0.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(loader):\n",
        "            if 'noise' in batch:\n",
        "                noise = batch['noise'].to(net0.device)\n",
        "            else:\n",
        "                noise = None\n",
        "            answers.append(net0(batch['input_ids'].to(net0.device), batch['attention_mask'].to(net0.device),\n",
        "                                batch['begin'].to(net0.device), batch['end'].to(net0.device),\n",
        "                                retain=False, noise=noise).cpu().numpy())\n",
        "            embeddings.append(net0.span_embeddings.cpu().numpy())\n",
        "            y.append(batch['y'].cpu().numpy())\n",
        "            score.append(batch['score'].cpu().numpy())\n",
        "            begin.append(batch['begin'].cpu().numpy())\n",
        "            end.append(batch['end'].cpu().numpy())\n",
        "    embeddings = np.concatenate(embeddings, axis=0)\n",
        "    answers = np.concatenate(answers, axis=0)\n",
        "    y = np.concatenate(y, axis=0)\n",
        "    score = np.concatenate(score, axis=0)\n",
        "    begin = np.concatenate(begin, axis=0)\n",
        "    end = np.concatenate(end, axis=0)\n",
        "    others = answers.copy()\n",
        "    others[np.arange(len(answers)), [tag for tag in y]] = -1e20\n",
        "    margin = answers[np.arange(len(answers)), [tag for tag in y]] - answers[np.arange(len(answers)), others.argsort(axis=1)[:,-1]]\n",
        "    ids = np.array([i for i in range(len(y)) if tags[y[i]] != 'O'])\n",
        "    return embeddings, answers, y, ids, margin, score, begin, end\n",
        "\n",
        "def calc_rocauc(diffs):\n",
        "    ans = {}\n",
        "    for key in diffs:\n",
        "        if key != 'val':\n",
        "            ans[key] = roc_auc_score(np.concatenate([np.zeros_like(diffs['val']), np.ones_like(diffs[key])]),\n",
        "                    np.concatenate([diffs['val'], diffs[key]]))\n",
        "    return ans\n",
        "\n",
        "def calc_mah(cov_matrix, means, embeddings):\n",
        "    scores = np.zeros((len(embeddings), len(means)))\n",
        "    for i in range(len(tags)):\n",
        "        scores[:, i] = ((embeddings - means[i][None,:]) @ np.linalg.inv(cov_matrix) @ (embeddings - means[i][None,:]).T)[range(len(embeddings)),\n",
        "        range(len(embeddings))]\n",
        "    return scores.min(axis=1)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-23T12:42:50.602503Z",
          "iopub.execute_input": "2025-10-23T12:42:50.602802Z",
          "iopub.status.idle": "2025-10-23T12:42:50.613166Z",
          "shell.execute_reply.started": "2025-10-23T12:42:50.602780Z",
          "shell.execute_reply": "2025-10-23T12:42:50.612193Z"
        },
        "id": "zzT35z2TTbtE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size     = config['val_batch_size'],\n",
        "    shuffle        = False,\n",
        "    drop_last      = False,\n",
        "    num_workers    = 0,\n",
        "    worker_init_fn = seed_worker,\n",
        "    generator      = g,\n",
        "    collate_fn     = collate_fn\n",
        ")\n",
        "\n",
        "res = process_set(net, train_loader)\n",
        "embeddings = res[0]\n",
        "y = res[2]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-23T12:42:50.614524Z",
          "iopub.execute_input": "2025-10-23T12:42:50.614774Z",
          "iopub.status.idle": "2025-10-23T12:46:57.326548Z",
          "shell.execute_reply.started": "2025-10-23T12:42:50.614753Z",
          "shell.execute_reply": "2025-10-23T12:46:57.325576Z"
        },
        "colab": {
          "referenced_widgets": [
            "bda5cc60bc684fe1990af744bdfee7d4"
          ]
        },
        "id": "o5Bk1ySmTbtF",
        "outputId": "87a2fd3c-3e43-4fc2-9dbc-d1355826458e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/987 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bda5cc60bc684fe1990af744bdfee7d4"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "cov_matrix = np.cov(embeddings, rowvar=False)\n",
        "means = []\n",
        "for i in range(len(tags)):\n",
        "    means.append(embeddings[y == i].mean(axis=0))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-23T12:46:57.327864Z",
          "iopub.execute_input": "2025-10-23T12:46:57.328219Z",
          "iopub.status.idle": "2025-10-23T12:46:57.541535Z",
          "shell.execute_reply.started": "2025-10-23T12:46:57.328188Z",
          "shell.execute_reply": "2025-10-23T12:46:57.540822Z"
        },
        "id": "mrb_pLJJTbtF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "processed = {}\n",
        "other_loaders['val'] = val_dataloader\n",
        "for key in ['val', 'noise', 'drug_dosage', 'drug_effect']:\n",
        "    processed[key] = process_set(net, other_loaders[key])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-22T17:02:30.299558Z",
          "iopub.execute_input": "2025-10-22T17:02:30.299886Z",
          "iopub.status.idle": "2025-10-22T17:08:21.859713Z",
          "shell.execute_reply.started": "2025-10-22T17:02:30.299860Z",
          "shell.execute_reply": "2025-10-22T17:08:21.858980Z"
        },
        "colab": {
          "referenced_widgets": [
            "00917e8998f747c5bc7ce4269a82fb69",
            "0926dfb6fa994767bd1c226a634e70dd",
            "999b4ef4889642b09711cd35fd09318b",
            "bcc09fa643444c9caedf0a3781d4a2c2"
          ]
        },
        "id": "LIiw1xovTbtG",
        "outputId": "d0a5e333-970f-4f78-fc6f-008c06ad7c65"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/413 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "00917e8998f747c5bc7ce4269a82fb69"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/288 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0926dfb6fa994767bd1c226a634e70dd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/32 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "999b4ef4889642b09711cd35fd09318b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/686 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bcc09fa643444c9caedf0a3781d4a2c2"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "processed = {}\n",
        "other_loaders['val'] = val_dataloader\n",
        "for key in ['val']:\n",
        "    processed[key] = process_set(net, other_loaders[key])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-23T12:46:57.543256Z",
          "iopub.execute_input": "2025-10-23T12:46:57.543578Z",
          "iopub.status.idle": "2025-10-23T12:48:40.686051Z",
          "shell.execute_reply.started": "2025-10-23T12:46:57.543545Z",
          "shell.execute_reply": "2025-10-23T12:48:40.685336Z"
        },
        "colab": {
          "referenced_widgets": [
            "ef7b6dc6e6fb45cf96cab69daa174591"
          ]
        },
        "id": "use9MF8TTbtH",
        "outputId": "e042320e-39a6-424b-80ef-3c2c6e196cec"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/413 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ef7b6dc6e6fb45cf96cab69daa174591"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [eval_dataset[i]['text'] for i in range(len(eval_dataset))]\n",
        "spans = []\n",
        "for i in range(len(eval_dataset)):\n",
        "    el = eval_dataset[i]\n",
        "    begin = el['begin']\n",
        "    end = el['end']\n",
        "    spans.append(tokenizer.decode(el['input_ids'][begin:end]))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-23T12:48:40.687270Z",
          "iopub.execute_input": "2025-10-23T12:48:40.687512Z",
          "iopub.status.idle": "2025-10-23T12:48:40.838550Z",
          "shell.execute_reply.started": "2025-10-23T12:48:40.687490Z",
          "shell.execute_reply": "2025-10-23T12:48:40.837626Z"
        },
        "id": "LcwfmpRfTbtH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "grads = pickle.load(open('/kaggle/input/other-grads-s-endpoint/grads.pkl', 'rb'))\n",
        "diffs_vog = {}\n",
        "for key in ['val', 'noise', 'drug_dosage', 'drug_effect']:\n",
        "    diffs_vog[key] = np.array(grads[key])[1:].var(axis=0).mean(axis=1)\n",
        "# diffs_vog['val'] = diffs_vog['val'][processed['val'][3]]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-22T17:09:16.135947Z",
          "iopub.execute_input": "2025-10-22T17:09:16.136243Z",
          "iopub.status.idle": "2025-10-22T17:10:01.881822Z",
          "shell.execute_reply.started": "2025-10-22T17:09:16.136222Z",
          "shell.execute_reply": "2025-10-22T17:10:01.881051Z"
        },
        "id": "2_MT946kTbtH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "grads = pickle.load(open('/kaggle/input/other-grads-b-mean/grads.pkl', 'rb'))\n",
        "diffs_vog = {}\n",
        "for key in ['val']:\n",
        "    diffs_vog[key] = np.array(grads[key])[1:].var(axis=0).mean(axis=1)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-23T12:48:40.839455Z",
          "iopub.execute_input": "2025-10-23T12:48:40.839749Z",
          "iopub.status.idle": "2025-10-23T12:48:56.815171Z",
          "shell.execute_reply.started": "2025-10-23T12:48:40.839716Z",
          "shell.execute_reply": "2025-10-23T12:48:56.814407Z"
        },
        "id": "t53jTbuyTbtI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "margin_diffs = {}\n",
        "abs_margin_diffs = {}\n",
        "mh_diffs = {}\n",
        "for key in processed:\n",
        "    margin_diffs[key] = -processed[key][4]\n",
        "    abs_margin_diffs[key] = -np.abs(processed[key][4])\n",
        "    mh_diffs[key] = calc_mah(cov_matrix, means, processed[key][0])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-23T12:48:56.816125Z",
          "iopub.execute_input": "2025-10-23T12:48:56.816448Z",
          "iopub.status.idle": "2025-10-23T12:49:03.033768Z",
          "shell.execute_reply.started": "2025-10-23T12:48:56.816416Z",
          "shell.execute_reply": "2025-10-23T12:49:03.032855Z"
        },
        "id": "J3DmETUOTbtI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "ids = processed['val'][3]\n",
        "diffs = diffs_vog['val']\n",
        "for i in diffs[ids].argsort()[-10:]:\n",
        "    print(diffs[ids[i]], spans[ids[i]], tags[processed['val'][2][ids[i]]], tags[processed['val'][1][ids[i]].argmax()])\n",
        "    print(texts[ids[i]])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-23T12:49:03.034623Z",
          "iopub.execute_input": "2025-10-23T12:49:03.034922Z",
          "iopub.status.idle": "2025-10-23T12:49:03.050508Z",
          "shell.execute_reply.started": "2025-10-23T12:49:03.034898Z",
          "shell.execute_reply": "2025-10-23T12:49:03.049644Z"
        },
        "id": "58mnRjS-TbtI",
        "outputId": "a6420bcd-f6b6-49dc-a9b5-b2aea19b5db7"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "4.169192010762451e-07 home office org O\nThe Home Office organized seven working groups to prepare the report on the root causes of the July 7 suicide attacks by British Muslims that killed 52 people in London .\n4.2320633356716694e-07 cabinet org org\nHe says any measures must have Cabinet approval .\n4.304048317013869e-07 helmund province geo geo\nThey say the policemen disappeared in Helmund Province .\n4.3479030695632983e-07 helmand geo geo\nAn exchange of gunfire between British troops and Afghan police in southern Helmand province Thursday left an Afghan policeman dead .\n4.3940648382627613e-07 tomb geo O\nMr. Bush will make remarks and lay a wreath at the Tomb of the Unknowns which contains the remains of unidentified U.S. service members who died in World Wars I and II - and in the Korean War .\n4.401264387790166e-07 helmand geo geo\nThe British Defense Ministry says a British soldier serving with the NATO force in Afghanistan has been shot dead in southern Helmand province .\n4.4484732388508447e-07 helmand geo geo\nPhotographer Gabriele Torsello was kidnapped in Helmand province last week .\n4.613948822903112e-07 ramadan per tim\nAuthorities say the blast killed five members of Ramadan 's family and two of his guards .\n5.10589887226445e-07 earlier tim O\nIt is not clear if it this is the same incident that claimed lives of supporters of Pakistani President Pervez Musharraf 's party , as reported earlier .\n5.425810072211203e-07 army org org\nAn Afghan Army spokesman said the troops were traveling towards the nearby Pakistani border when their vehicle hit the mine .\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "diffs = margin_diffs['val']\n",
        "for i in diffs[ids].argsort()[-10:]:\n",
        "    print(diffs[ids[i]], spans[ids[i]], tags[processed['val'][2][ids[i]]], tags[processed['val'][1][ids[i]].argmax()])\n",
        "    print(texts[ids[i]])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-23T12:49:03.052396Z",
          "iopub.execute_input": "2025-10-23T12:49:03.052699Z",
          "iopub.status.idle": "2025-10-23T12:49:03.066276Z",
          "shell.execute_reply.started": "2025-10-23T12:49:03.052650Z",
          "shell.execute_reply": "2025-10-23T12:49:03.065346Z"
        },
        "id": "DAWF0_XiTbtJ",
        "outputId": "a4c64aaa-da13-4d48-bfe4-13d2bd65e501"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "7.6897073 ebola nat geo\nIn the past , the Democratic Republic of Congo has endured outbreaks of both Marburg and Ebola , two types of hemorrhagic fever caused by viruses that can attack the central nervous system and cause bleeding from the eyes , ears , and other parts of the body .\n7.8210087 arab geo gpe\nPakistan 's army has conducted a series of counter-terrorism operations in North and South Waziristan in the past three years , aimed at trapping Arab , Afghan and Central Asian militants with links to the Taliban and al-Qaida .\n7.902258 azerbaijani geo gpe\nThe current global economic slowdown presents some challenges for the Azerbaijani economy as oil prices remain below their mid-2008 highs , highlighting Azerbaijan 's reliance on energy exports and lackluster attempts to diversify its economy .\n7.9583364 british org gpe\nOriginally settled by Polynesian emigrants from surrounding island groups , the Tokelau Islands were made a British protectorate in 1889 .\n7.9825544 mw org O\nNepal has considerable scope for exploiting its potential in hydropower , with an estimated 42,000 MW of feasible capacity , but political instability hampers foreign investment .\n8.0583515 british org gpe\nBritish Finance Minister Gordon Brown has outlined a series of measures to halt the funding of terrorists .\n8.143003 six tim O\nChina 's foreign ministry has denied reports that Chinese banks loaned six billion dollars to a Russian bank to buy the main oil production unit of the Yukos energy company .\n8.29665 pakistani org gpe\nIt is not clear if it this is the same incident that claimed lives of supporters of Pakistani President Pervez Musharraf 's party , as reported earlier .\n8.6114435 24 tim O\nIsraeli troops arrested 24 Palestinians , including members of Hamas and Islamic Jihad , in raids overnight .\n9.129577 for org O\nFormer Liberian Finance Minister Ellen Johnson-Sirleaf won about 60 percent of the vote , to 40 percent for Mr. Weah , a former soccer ( football ) star .\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "diffs = abs_margin_diffs['val']\n",
        "for i in diffs[ids].argsort()[-10:]:\n",
        "    print(diffs[ids[i]], spans[ids[i]], tags[processed['val'][2][ids[i]]], tags[processed['val'][1][ids[i]].argmax()])\n",
        "    print(texts[ids[i]])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-23T12:49:03.067076Z",
          "iopub.execute_input": "2025-10-23T12:49:03.067368Z",
          "iopub.status.idle": "2025-10-23T12:49:03.078554Z",
          "shell.execute_reply.started": "2025-10-23T12:49:03.067333Z",
          "shell.execute_reply": "2025-10-23T12:49:03.077863Z"
        },
        "id": "9Uz9_gxbTbtJ",
        "outputId": "b81773c6-bdb1-4149-da2b-78643b66d6af"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "-0.023964643 bild am sonntag org org\nMs. Merkel told the Bild am Sonntag newspaper the government is doing all it can to rescue Susanne Osthoff and her Iraqi driver , who disappeared nine days ago , on November 25 .\n-0.017394066 general bozize org per\nThough the government has the tacit support of civil society groups and the main parties , a wide field of candidates contested the municipal , legislative , and presidential elections held in March and May of 2005 in which General BOZIZE was affirmed as president .\n-0.016691208 uganda ' s health ministry org org\nUganda 's Health Ministry says the country has confirmed its first case of H1N1 swine flu .\n-0.016061783 \" caliph of cologne org O\nMetin Kaplan , also known as the \" Caliph of Cologne , \" faces charges of trying to overthrow Turkey 's constitutional order .\n-0.015525579 u. n. org org\nHe said in a statement that he is deeply concerned by continued threats against U.N. personnel and by reports that more violent protests and attacks are being planned .\n-0.009648085 dejan \" bugsy \" milenkovic per per\nDejan \" Bugsy \" Milenkovic told a Belgrade court Thursday that Nebojsa Covic was aware of the conspiracy .\n-0.005389929 abdul rahman al - attiya per per\nBefore the summit , the Gulf Cooperation Council 's secretary-general ( Abdul Rahman al-Attiya ) said the group trusts Iran , but wants to ensure that a nuclear power plant is not built close to the waters of member states .\n-0.0043828487 aung san suu kyi geo org\nA statement says the secretary-general also reiterated his call for the release of political prisoners and to lift restrictions on detained pro-Democracy advocate Aung San Suu Kyi .\n-0.002926588 banjul geo org\nA well-known journalist in Gambia has been shot and killed in the capital , Banjul .\n-0.0013507009 , org O\nThe influential soul , rock , rap and funk musician has made more than 50 albums , selling millions worldwide , since he broke onto the scene with \" Please , Please , Please \" in 1956 .\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "diffs = mh_diffs['val']\n",
        "for i in diffs[ids].argsort()[-10:]:\n",
        "    print(diffs[ids[i]], spans[ids[i]], tags[processed['val'][2][ids[i]]], tags[processed['val'][1][ids[i]].argmax()])\n",
        "    print(texts[ids[i]])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-23T12:49:03.079477Z",
          "iopub.execute_input": "2025-10-23T12:49:03.079823Z",
          "iopub.status.idle": "2025-10-23T12:49:03.091458Z",
          "shell.execute_reply.started": "2025-10-23T12:49:03.079799Z",
          "shell.execute_reply": "2025-10-23T12:49:03.090781Z"
        },
        "id": "2SzVgHmZTbtJ",
        "outputId": "cd46379e-8aee-4ab2-ff3c-04c426a5ec8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "9366.179746382695 from tim tim\nA national shopping research group , ShopperTrak RCT corp. , reported Friday 's total sales at $ 8 billion , down about 0.9 percent from last year .\n9659.56802364299 people gpe org\nThe modern country of Mongolia , however , represents only part of the Mongols ' historical homeland ; more ethnic Mongolians live in the Inner Mongolia Autonomous Region in the People 's Republic of China than in Mongolia .\n10003.488265525782 tomb geo O\nMr. Bush will make remarks and lay a wreath at the Tomb of the Unknowns which contains the remains of unidentified U.S. service members who died in World Wars I and II - and in the Korean War .\n10027.933075800538 corruption org org\nThe report also calls on African governments to commit to transparency and to ratify the U.N. Covenant on Corruption .\n10596.28947828256 greek art gpe\nThe busy season meant forecasters exhausted their list of names , forcing them to use the Greek alphabet to name storms for the first time .\n11485.539640299976 please art org\nThe influential soul , rock , rap and funk musician has made more than 50 albums , selling millions worldwide , since he broke onto the scene with \" Please , Please , Please \" in 1956 .\n11486.20460693445 new tim tim\nDuring the new year celebrations , people often give gifts to family and friends .\n11960.843028856703 please art org\nThe influential soul , rock , rap and funk musician has made more than 50 albums , selling millions worldwide , since he broke onto the scene with \" Please , Please , Please \" in 1956 .\n12859.167442909908 please art org\nThe influential soul , rock , rap and funk musician has made more than 50 albums , selling millions worldwide , since he broke onto the scene with \" Please , Please , Please \" in 1956 .\n16342.345374517958 , org O\nThe influential soul , rock , rap and funk musician has made more than 50 albums , selling millions worldwide , since he broke onto the scene with \" Please , Please , Please \" in 1956 .\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(calc_rocauc(diffs_vog))\n",
        "print(calc_rocauc(margin_diffs))\n",
        "print(calc_rocauc(abs_margin_diffs))\n",
        "print(calc_rocauc(mh_diffs))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-22T19:22:29.269092Z",
          "iopub.execute_input": "2025-10-22T19:22:29.269315Z",
          "iopub.status.idle": "2025-10-22T19:22:29.275599Z",
          "shell.execute_reply.started": "2025-10-22T19:22:29.269294Z",
          "shell.execute_reply": "2025-10-22T19:22:29.274851Z"
        },
        "id": "3waRujuATbtJ",
        "outputId": "cf010ee1-5245-41f0-825d-c655dbccc456"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "{}\n{}\n{}\n{}\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(spearmanr(diffs_vog['val'], margin_diffs['val']))\n",
        "print(spearmanr(diffs_vog['val'], abs_margin_diffs['val']))\n",
        "print(spearmanr(diffs_vog['val'], mh_diffs['val']))\n",
        "print(spearmanr(margin_diffs['val'], abs_margin_diffs['val']))\n",
        "print(spearmanr(margin_diffs['val'], mh_diffs['val']))\n",
        "print(spearmanr(abs_margin_diffs['val'], mh_diffs['val']))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-05T19:54:17.247787Z",
          "iopub.execute_input": "2025-10-05T19:54:17.248080Z",
          "iopub.status.idle": "2025-10-05T19:54:17.275006Z",
          "shell.execute_reply.started": "2025-10-05T19:54:17.248051Z",
          "shell.execute_reply": "2025-10-05T19:54:17.274328Z"
        },
        "id": "61idi5oSTbtK",
        "outputId": "2e4f4923-23bb-4019-f6b9-5add57bbb93f"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "SignificanceResult(statistic=0.6758830642461333, pvalue=0.0)\nSignificanceResult(statistic=0.6441229857305452, pvalue=0.0)\nSignificanceResult(statistic=0.39805498436710224, pvalue=8.599102796705937e-250)\nSignificanceResult(statistic=0.9654502156000898, pvalue=0.0)\nSignificanceResult(statistic=0.2031913925699588, pvalue=1.5864339015325852e-62)\nSignificanceResult(statistic=0.19619873025088622, pvalue=2.4443886817512198e-58)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(spearmanr(diffs_vog['val'], 1-processed['val'][5]))\n",
        "print(spearmanr(margin_diffs['val'], 1-processed['val'][5]))\n",
        "print(spearmanr(abs_margin_diffs['val'], 1-processed['val'][5]))\n",
        "print(spearmanr(mh_diffs['val'], 1-processed['val'][5]))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-05T19:54:17.276648Z",
          "iopub.execute_input": "2025-10-05T19:54:17.276903Z",
          "iopub.status.idle": "2025-10-05T19:54:17.292198Z",
          "shell.execute_reply.started": "2025-10-05T19:54:17.276881Z",
          "shell.execute_reply": "2025-10-05T19:54:17.291550Z"
        },
        "id": "uN3c-Qd-TbtK",
        "outputId": "dc14b5af-cd07-406f-f30c-3d3237c27d73"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "SignificanceResult(statistic=0.011747357534651006, pvalue=0.33968372929725743)\nSignificanceResult(statistic=0.01560611012005201, pvalue=0.20463666021217125)\nSignificanceResult(statistic=0.014843153353402128, pvalue=0.2276508580262295)\nSignificanceResult(statistic=0.006459881217910198, pvalue=0.5995641909510832)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "mask = processed['val'][5] < 0.7\n",
        "print(ks_2samp(diffs_vog['val'][~mask], diffs_vog['val'][mask]))\n",
        "print(ks_2samp(margin_diffs['val'][~mask], margin_diffs['val'][mask]))\n",
        "print(ks_2samp(abs_margin_diffs['val'][~mask], abs_margin_diffs['val'][mask]))\n",
        "print(ks_2samp(mh_diffs['val'][~mask], mh_diffs['val'][mask]))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-05T19:54:17.293207Z",
          "iopub.execute_input": "2025-10-05T19:54:17.293435Z",
          "iopub.status.idle": "2025-10-05T19:54:17.305101Z",
          "shell.execute_reply.started": "2025-10-05T19:54:17.293415Z",
          "shell.execute_reply": "2025-10-05T19:54:17.304445Z"
        },
        "id": "V-U5RndlTbtL",
        "outputId": "e5059cf7-797b-4159-9e94-d21cf4a1e2ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "KstestResult(statistic=0.4585984045238817, pvalue=0.11294687977040595, statistic_location=1.8456918788426468e-08, statistic_sign=1)\nKstestResult(statistic=0.4502171059274967, pvalue=0.1253603096277013, statistic_location=-3.1282942, statistic_sign=1)\nKstestResult(statistic=0.47702716348581237, pvalue=0.08925335592223553, statistic_location=-3.1282942, statistic_sign=1)\nKstestResult(statistic=0.2952135716449561, pvalue=0.5761146385398366, statistic_location=739.8628451785771, statistic_sign=1)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(diffs_vog['val'][~mask].mean(), diffs_vog['val'][mask].mean())\n",
        "print(margin_diffs['val'][~mask].mean(), margin_diffs['val'][mask].mean())\n",
        "print(abs_margin_diffs['val'][~mask].mean(), abs_margin_diffs['val'][mask].mean())\n",
        "print(mh_diffs['val'][~mask].mean(), mh_diffs['val'][mask].mean())"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-05T19:54:17.305685Z",
          "iopub.execute_input": "2025-10-05T19:54:17.305905Z",
          "iopub.status.idle": "2025-10-05T19:54:17.317058Z",
          "shell.execute_reply.started": "2025-10-05T19:54:17.305887Z",
          "shell.execute_reply": "2025-10-05T19:54:17.316312Z"
        },
        "id": "cVKnvpReTbtM",
        "outputId": "02905865-1571-46e6-a3e6-819e00f3a4c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "1.2005555081930867e-07 7.093571001935776e-08\n-5.194937 -3.1974075\n-5.6114206 -4.1497297\n1944.2404437000073 1763.2661517050146\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(roc_auc_score(np.concatenate([np.zeros(len(processed['val'][5]) - mask.sum()), np.ones(mask.sum())]),\n",
        "                    np.concatenate([diffs_vog['val'][~mask], diffs_vog['val'][mask]])))\n",
        "print(roc_auc_score(np.concatenate([np.zeros(len(processed['val'][5]) - mask.sum()), np.ones(mask.sum())]),\n",
        "                    np.concatenate([margin_diffs['val'][~mask], margin_diffs['val'][mask]])))\n",
        "print(roc_auc_score(np.concatenate([np.zeros(len(processed['val'][5]) - mask.sum()), np.ones(mask.sum())]),\n",
        "                    np.concatenate([abs_margin_diffs['val'][~mask], abs_margin_diffs['val'][mask]])))\n",
        "print(roc_auc_score(np.concatenate([np.zeros(len(processed['val'][5]) - mask.sum()), np.ones(mask.sum())]),\n",
        "                    np.concatenate([mh_diffs['val'][~mask], mh_diffs['val'][mask]])))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-05T19:54:17.317878Z",
          "iopub.execute_input": "2025-10-05T19:54:17.318165Z",
          "iopub.status.idle": "2025-10-05T19:54:17.341920Z",
          "shell.execute_reply.started": "2025-10-05T19:54:17.318137Z",
          "shell.execute_reply": "2025-10-05T19:54:17.341259Z"
        },
        "id": "C8nAQPHdTbtM",
        "outputId": "9b719cf9-cefb-49f8-9166-f6cf9b57aff2"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "0.6126426335453903\n0.6495506412198323\n0.642254872260931\n0.5619256790871453\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    }
  ]
}